<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>LONGLORA | Sunset</title>
<meta name="keywords" content="Quantization, Paper">
<meta name="description" content="긴 context를 위한 모델 만들기">
<meta name="author" content="">
<link rel="canonical" href="https://new-sunset-shimmer.github.io/LONGLORA/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://new-sunset-shimmer.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://new-sunset-shimmer.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://new-sunset-shimmer.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://new-sunset-shimmer.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://new-sunset-shimmer.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://new-sunset-shimmer.github.io/LONGLORA/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><style>
    @media screen and (min-width: 769px) {

         
        .post-content input[type="checkbox"]:checked~label>img {
            transform: scale(1.6);
            cursor: zoom-out;
            position: relative;
            z-index: 999;
        }

        .post-content img.zoomCheck {
            transition: transform 0.15s ease;
            z-index: 999;
            cursor: zoom-in;
        }
    }
</style><meta property="og:title" content="LONGLORA" />
<meta property="og:description" content="긴 context를 위한 모델 만들기" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://new-sunset-shimmer.github.io/LONGLORA/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-12-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-12-12T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="LONGLORA"/>
<meta name="twitter:description" content="긴 context를 위한 모델 만들기"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://new-sunset-shimmer.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "LONGLORA",
      "item": "https://new-sunset-shimmer.github.io/LONGLORA/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LONGLORA",
  "name": "LONGLORA",
  "description": "긴 context를 위한 모델 만들기",
  "keywords": [
    "Quantization", "Paper"
  ],
  "articleBody": "2309.12307 (arxiv.org)\nLONGLORA: EFFICIENT FINE-TUNING OF LONGCONTEXT LARGE LANGUAGE MODEL\nReleased Date : ICLR 2024\nReview Date : 2024 10 20\n긴 context를 위한 모델 만들기\nMotivation LLM의 놀라운 성능에도 불구하고 높은 계산량, 큰 사이즈등의 문제가 존재한다. 또한 사전학습에서 정한 최대 길이 이상의 context를 입력으로 받을 경우 제대로 된 성능을 못보여주는 단점도 존재한다. 해당 문제를 해결하기 위해서는 context 길이를 늘려서 continious training을 해야하지만 앞서 언급한 단점에 인해서 쉽지 않다. 본 논문에서는 긴 context길이를 위해서 효율적인 학습 방법을 제안한다. Research questions 긴 context를 위한 효율적인 학습 방법이 존재하는가? Methodology 해당 논문에서는 효율적인 학습을 위해 기존에 쓰이는 lora(LOw Rank Adaptation)을 채용하는 동시에 오직 Lora만으로 학습시 성능이 나오지 않으며 Embedding 차원을 따로 학습 시키지 않으며 결국 context 길이가 제한 되기에 Embedding 차원 그리고 새로운 사이즈를 위해 normalize layer도 학습한다. 어텐션 Layer의 비효율성을 제거 하기 위해서 해당 논문에서는 Shifted Sparse Attention을 제안했다. Shifted Sparse Attention(s^2-Attn) : Context를 Group으로 묶고 head들을 나눈다. 어느 한 head 그룹은 Context Group의 절반 사이즈 만큼 token의 index를 바꾼다. 이로 인해서 Context를 나눠도 head끼리 정보 교환이 이루워져 성능이 올라간다. Main result 모델은 Llama2 모델을 사전학습을 진행했다. 7B은 100K context size, 13B은 65536, 10B은 32768로 설정했으며 LR은 7B,13B에 2 x 10^-5로 설정해줬다. 데이터셋은 Redpajama로 학습 평가는 PG19, cleaned Arxiv Math proof-pile dataset을 섰다. 또한 embedding Layer를 늘리기 위한 쓴 Position Interpolation방법론에서 평가를 진행한 데이터셋들도 재사용했다. 오직 LoRA만 쓰는건 비효율적이라는 것을 보여주는 table Retrieval 성능도 평가하였다. Personal thought S^2 Attn은 마지막에 contcate 될떄만 정보를 교환하는가.\nembedding을 다른 방식으로 바꾸면 어떻게 되는가. 예를 들어 absolute position encoding으로 바꾸면 속도가 더 올라가지 않을까?\n",
  "wordCount" : "249",
  "inLanguage": "en",
  "datePublished": "2024-12-12T00:00:00Z",
  "dateModified": "2024-12-12T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://new-sunset-shimmer.github.io/LONGLORA/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Sunset",
    "logo": {
      "@type": "ImageObject",
      "url": "https://new-sunset-shimmer.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://new-sunset-shimmer.github.io/" accesskey="h" title="Sunset (Alt + H)">Sunset</a>
            <div class="logo-switches">
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://new-sunset-shimmer.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://new-sunset-shimmer.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://new-sunset-shimmer.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://new-sunset-shimmer.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      LONGLORA
    </h1>
    <div class="post-meta"><span title='2024-12-12 00:00:00 +0000 UTC'>December 12, 2024</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#motivation" aria-label="Motivation">Motivation</a></li>
                <li>
                    <a href="#research-questions" aria-label="Research questions">Research questions</a></li>
                <li>
                    <a href="#methodology" aria-label="Methodology">Methodology</a></li>
                <li>
                    <a href="#main-result" aria-label="Main result">Main result</a></li>
                <li>
                    <a href="#personal-thought" aria-label="Personal thought">Personal thought</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><a href="https://arxiv.org/pdf/2309.12307">2309.12307 (arxiv.org)</a></p>
<blockquote>
<p>LONGLORA: EFFICIENT FINE-TUNING OF LONGCONTEXT LARGE LANGUAGE MODEL</p>
</blockquote>
<blockquote>
<p>Released Date : ICLR 2024</p>
</blockquote>
<blockquote>
<p>Review Date : 2024 10 20</p>
</blockquote>
<p>긴 context를 위한 모델 만들기</p>
<h3 id="motivation">Motivation<a hidden class="anchor" aria-hidden="true" href="#motivation">#</a></h3>
<ul>
<li>LLM의 놀라운 성능에도 불구하고 높은 계산량, 큰 사이즈등의 문제가 존재한다. 또한 사전학습에서 정한 최대 길이 이상의 context를 입력으로 받을 경우 제대로 된 성능을 못보여주는 단점도 존재한다. 해당 문제를 해결하기 위해서는 context 길이를 늘려서 continious training을 해야하지만 앞서 언급한 단점에 인해서 쉽지 않다. 본 논문에서는 긴 context길이를 위해서 효율적인 학습 방법을 제안한다.</li>
</ul>
<p>

<input type="checkbox" id="zoomCheck-b1d40" hidden>
<label for="zoomCheck-b1d40">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-80d2-9005-c5d7721d256b.png#center" alt=""  />
</label></p>
<h3 id="research-questions">Research questions<a hidden class="anchor" aria-hidden="true" href="#research-questions">#</a></h3>
<ul>
<li>긴 context를 위한 효율적인 학습 방법이 존재하는가?</li>
</ul>
<h3 id="methodology">Methodology<a hidden class="anchor" aria-hidden="true" href="#methodology">#</a></h3>
<ul>
<li>해당 논문에서는 효율적인 학습을 위해 기존에 쓰이는 lora(LOw Rank Adaptation)을 채용하는 동시에 오직 Lora만으로 학습시 성능이 나오지 않으며 Embedding 차원을 따로 학습 시키지 않으며 결국 context 길이가 제한 되기에 Embedding 차원 그리고 새로운 사이즈를 위해 normalize layer도 학습한다. 어텐션 Layer의 비효율성을 제거 하기 위해서 해당 논문에서는 Shifted Sparse Attention을 제안했다.</li>
</ul>
<p>

<input type="checkbox" id="zoomCheck-65ea8" hidden>
<label for="zoomCheck-65ea8">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-80e2-a263-c3cb94b2cbed.png#center" alt=""  />
</label></p>
<ul>
<li>Shifted Sparse Attention(s^2-Attn) : Context를 Group으로 묶고 head들을 나눈다. 어느 한 head 그룹은 Context Group의 절반 사이즈 만큼 token의 index를 바꾼다. 이로 인해서 Context를 나눠도 head끼리 정보 교환이 이루워져 성능이 올라간다.</li>
</ul>
<p>

<input type="checkbox" id="zoomCheck-83a84" hidden>
<label for="zoomCheck-83a84">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-80b2-8351-e1d91f81ecdd.png#center" alt=""  />
</label></p>
<p>

<input type="checkbox" id="zoomCheck-31b6b" hidden>
<label for="zoomCheck-31b6b">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-8052-931b-d0ee885edf5e.png#center" alt=""  />
</label></p>
<h3 id="main-result">Main result<a hidden class="anchor" aria-hidden="true" href="#main-result">#</a></h3>
<ul>
<li>모델은 Llama2 모델을 사전학습을 진행했다. 7B은 100K context size, 13B은 65536, 10B은 32768로 설정했으며 LR은 7B,13B에 2 x 10^-5로 설정해줬다. 데이터셋은 Redpajama로 학습 평가는 PG19, cleaned Arxiv Math proof-pile dataset을 섰다. 또한 embedding Layer를 늘리기 위한 쓴 Position Interpolation방법론에서 평가를 진행한 데이터셋들도 재사용했다.</li>
</ul>
<p>

<input type="checkbox" id="zoomCheck-3f091" hidden>
<label for="zoomCheck-3f091">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-80c2-9952-d8c8f1273a45.png#center" alt=""  />
</label></p>
<hr>
<ul>
<li>오직 LoRA만 쓰는건 비효율적이라는 것을 보여주는 table</li>
</ul>
<p>

<input type="checkbox" id="zoomCheck-9ea2a" hidden>
<label for="zoomCheck-9ea2a">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-8083-8ac0-f3ff71577aa0.png#center" alt=""  />
</label></p>
<p>

<input type="checkbox" id="zoomCheck-d0f99" hidden>
<label for="zoomCheck-d0f99">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-80bd-9a82-e6bd5feab746.png#center" alt=""  />
</label></p>
<ul>
<li>Retrieval 성능도 평가하였다.</li>
</ul>
<p>

<input type="checkbox" id="zoomCheck-f530b" hidden>
<label for="zoomCheck-f530b">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-8032-96af-c24a863b37aa.png#center" alt=""  />
</label></p>
<p>

<input type="checkbox" id="zoomCheck-3b5de" hidden>
<label for="zoomCheck-3b5de">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-80e2-a269-c9c6b358cd38.png#center" alt=""  />
</label></p>
<p>

<input type="checkbox" id="zoomCheck-7c105" hidden>
<label for="zoomCheck-7c105">
    <img class="zoomCheck" loading="lazy" decoding="async" src="/images/15a415f9-e659-80a5-aae7-f06cff59524e.png#center" alt=""  />
</label></p>
<h3 id="personal-thought">Personal thought<a hidden class="anchor" aria-hidden="true" href="#personal-thought">#</a></h3>
<ol>
<li>
<p>S^2 Attn은 마지막에 contcate 될떄만 정보를 교환하는가.</p>
</li>
<li>
<p>embedding을 다른 방식으로 바꾸면 어떻게 되는가. 예를 들어 absolute position encoding으로 바꾸면 속도가 더 올라가지 않을까?</p>
</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://new-sunset-shimmer.github.io/tags/quantization/">Quantization</a></li>
      <li><a href="https://new-sunset-shimmer.github.io/tags/paper/">Paper</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://new-sunset-shimmer.github.io/">Sunset</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
